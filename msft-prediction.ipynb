{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxf3wCvR2THw9wscYlEIOv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavisRayM/msft-stock-prediction/blob/main/msft-prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 4"
      ],
      "metadata": {
        "id": "3VAv_0rZBSJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Author: Davis Muro\n",
        "\n",
        "For CPSC 5610\n",
        "\n",
        "Microsoft Stock Prediction"
      ],
      "metadata": {
        "id": "9oRwhV28BWFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "LvDyQuH2BvdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(25)\n",
        "tf.random.set_seed(25)"
      ],
      "metadata": {
        "id": "UDwf3pkmGrUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/MSFT.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "-jQ0kmQeB6HZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "85UPsF6KCABR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert `Date` to `DateTime`\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Sort dataframe by `Date` (Ascending)\n",
        "df.sort_values(by='Date', inplace=True, ascending=True)\n",
        "\n",
        "# Drop Adj Close\n",
        "df.drop(columns=['Adj Close'], inplace=True)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "YzIXm9j3CCjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Normalize numerical columns using MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "df[['Close', 'High', 'Low', 'Open', 'Volume']] = scaler.fit_transform(df[['Close', 'High', 'Low', 'Open', 'Volume']])\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "dtzWYYpcCOeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set `Date` as index; It's unique\n",
        "if (df.duplicated(subset=['Date']).sum() > 0):\n",
        "    assert False, \"Duplicate dates found\"\n",
        "\n",
        "df.set_index('Date', inplace=True)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "2Jj3pMV4DQFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "IVoKi-EFFIit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Windowing"
      ],
      "metadata": {
        "id": "o79YCkqkD3Gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = df.shape[0] * 80 // 100\n",
        "test_size = df.shape[0] - train_size\n",
        "train_size, test_size"
      ],
      "metadata": {
        "id": "ZC190Jh7DbTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a sliding window of N days (e.g., 20 days) to predict the next dayÊ¼s values.\n",
        "train_data = tf.data.Dataset.from_tensor_slices(df.values[:train_size])\n",
        "test_data = tf.data.Dataset.from_tensor_slices(df.values[:test_size])\n",
        "n_steps = 20\n",
        "window_length = n_steps + 1\n",
        "train_data = train_data.window(window_length, shift =1, drop_remainder=True )\n",
        "test_data = test_data.window(window_length, shift =1, drop_remainder=True )"
      ],
      "metadata": {
        "id": "ECtY9oMlFW9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for window in train_data.take(2):\n",
        "    t = list(window.as_numpy_iterator())\n",
        "    print(len(t))\n",
        "    print(t)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "pVP5cecSFtLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for window in test_data.take(2):\n",
        "    t = list(window.as_numpy_iterator())\n",
        "    print(len(t))\n",
        "    print(t)"
      ],
      "metadata": {
        "id": "S9xdKAnRNM4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_dataset(dataset, n):\n",
        "    dataset = dataset.prefetch(1)\n",
        "    for tensor in dataset.take(n):\n",
        "        print(tensor)\n",
        "train_data = train_data.flat_map(lambda window: window.batch(window_length))\n",
        "test_data = test_data.flat_map(lambda window: window.batch(window_length))\n",
        "\n",
        "show_dataset(train_data, 2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VaktwMgxGRG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_data = train_data.batch(batch_size)\n",
        "test_data = test_data.batch(batch_size)\n",
        "show_dataset(train_data, 2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "W21FErl5GgAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.map(lambda window: (window[:, :-1, :], window[:, -1, :]))\n",
        "test_data = test_data.map(lambda window: (window[:, :-1, :], window[:, -1, :]))\n",
        "show_dataset(train_data, 2)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_hIVtHEdHPw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape your input as (samples, timesteps, features) .\n",
        "train_data = train_data.prefetch(1)\n",
        "for X_batch, Y_batch in train_data.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "metadata": {
        "id": "v_3MIsOxIAIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = test_data.prefetch(1)\n",
        "for X_batch, Y_batch in test_data.take(1):\n",
        "    print(X_batch.shape, Y_batch.shape)"
      ],
      "metadata": {
        "id": "8CTxf6kRNXwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelling"
      ],
      "metadata": {
        "id": "IkdgbKAJKYfG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization, Layer\n",
        "from tensorflow.keras import activations\n",
        "\n",
        "class BatchNormSimpleRNN(Layer):\n",
        "    def __init__(self, units, return_sequences=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.simple_rnn = SimpleRNN(units, activation=None, return_sequences=return_sequences, **kwargs)\n",
        "        self.batch_norm = BatchNormalization()\n",
        "        self.activation = activations.tanh  # or any other activation you want\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        x = self.simple_rnn(inputs)\n",
        "        x = self.batch_norm(x, training=training)\n",
        "        x = self.activation(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "UlL_rj99Qj7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, LSTM, GRU, Input\n",
        "from typing import Tuple, List\n",
        "\n",
        "def create_model(kind: str = \"simple\", input_shape: Tuple[int, int, int] = (n_steps, 5), hidden_units: List = [128, 64]):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(Input(shape=input_shape))\n",
        "\n",
        "  if kind == \"simple\":\n",
        "    model.add(BatchNormSimpleRNN(hidden_units[0], return_sequences=(len(hidden_units) > 1), dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    for units in hidden_units[1:-1]:\n",
        "      model.add(BatchNormSimpleRNN(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    if len(hidden_units) > 1:\n",
        "      model.add(BatchNormSimpleRNN(hidden_units[-1], return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
        "  elif kind == \"lstm\":\n",
        "    model.add(LSTM(hidden_units[0], return_sequences=(len(hidden_units) > 1), dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    for units in hidden_units[1:-1]:\n",
        "      model.add(LSTM(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    if len(hidden_units) > 1:\n",
        "      model.add(LSTM(hidden_units[-1], return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
        "  elif kind == \"gru\":\n",
        "    model.add(GRU(hidden_units[0], return_sequences=(len(hidden_units) > 1), dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    for units in hidden_units[1:-1]:\n",
        "      model.add(GRU(units, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "    if len(hidden_units) > 1:\n",
        "      model.add(GRU(hidden_units[-1], return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
        "  else:\n",
        "    assert False, \"Unsupported kind: \" + kind\n",
        "\n",
        "  model.add(Dense(input_shape[1]))\n",
        "  model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
        "  return model"
      ],
      "metadata": {
        "id": "I7UEpXBUKsMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_mae',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "epochs = 20"
      ],
      "metadata": {
        "id": "OvYxcF-QN7Lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple = create_model(kind=\"simple\", hidden_units=[128, 64])\n",
        "simple.summary()"
      ],
      "metadata": {
        "id": "xKD0X9PEMPXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[early_stopping])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dzdYM62RMpF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(simple.history.history)\n",
        "result.head()"
      ],
      "metadata": {
        "id": "K4AsxOj9Od3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[['mae', 'val_mae']].plot(title=\"Mean Absolute Error vs Epoch\")"
      ],
      "metadata": {
        "id": "5O578PCxOgkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[['loss','val_loss']].plot(title=\"Loss vs Epoch\")"
      ],
      "metadata": {
        "id": "XnMsMMjsOoGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru = create_model(kind=\"gru\", hidden_units=[128, 64])\n",
        "gru.summary()"
      ],
      "metadata": {
        "id": "qSJMZe8FZ6W3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gru.fit(train_data, epochs=epochs, validation_data=test_data, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "2xMDgmvxZ-Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(simple.history.history)\n",
        "result.head()"
      ],
      "metadata": {
        "id": "XuvLsh06aKFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[['mae', 'val_mae']].plot(title=\"Mean Absolute Error vs Epoch\")"
      ],
      "metadata": {
        "id": "QEW9xpP9aKpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result[['loss','val_loss']].plot(title=\"Loss vs Epoch\")"
      ],
      "metadata": {
        "id": "r3djwwyiaOVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}